{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb0fc720",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "397d13e3-2d07-425a-9cfb-e6d6fafdde4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f96a5db",
   "metadata": {},
   "source": [
    "### In order to featch 20k+ posts, we decide to use the API and expand tags to all NLP related tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2dc337e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0952d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We collected the data from 65 unique tags [1,2]\n",
    "tags_to_fetch = [\n",
    "    # Core NLP tags\n",
    "    \"nlp\",\n",
    "    \"natural-language-processing\",\n",
    "    \"computational-linguistics\",\n",
    "\n",
    "    # Classification & analysis\n",
    "    \"text-classification\",\n",
    "    \"document-classification\",\n",
    "    \"sentiment-analysis\",\n",
    "    \"emotion-detection\",\n",
    "    \"text-mining\",\n",
    "    \"text-analytics\",\n",
    "\n",
    "    # Tokenization & text preprocessing\n",
    "    \"tokenization\",\n",
    "    \"named-entity-recognition\",\n",
    "    \"ner\",\n",
    "    \"pos-tagging\",\n",
    "    \"part-of-speech\",\n",
    "    \"lemmatization\",\n",
    "    \"stemming\",\n",
    "    \"stopwords\",\n",
    "    \"text-preprocessing\",\n",
    "    \"text-normalization\",\n",
    "\n",
    "    # Libraries & frameworks\n",
    "    \"spacy\",\n",
    "    \"nltk\",\n",
    "    \"gensim\",\n",
    "    \"huggingface\",\n",
    "    \"transformers\",\n",
    "    \"corenlp\",\n",
    "    \"stanza\",\n",
    "    \"flair\",\n",
    "    \"allennlp\",\n",
    "\n",
    "    # Models & embeddings\n",
    "    \"bert\",\n",
    "    \"roberta\",\n",
    "    \"gpt\",\n",
    "    \"language-model\",\n",
    "    \"word2vec\",\n",
    "    \"glove\",\n",
    "    \"fasttext\",\n",
    "    \"word-embeddings\",\n",
    "    \"sentence-embeddings\",\n",
    "    \"contextual-embeddings\",\n",
    "\n",
    "    # Information retrieval & similarity\n",
    "    \"tf-idf\",\n",
    "    \"information-retrieval\",\n",
    "    \"semantic-search\",\n",
    "    \"document-similarity\",\n",
    "    \"text-similarity\",\n",
    "    \"cosine-similarity\",\n",
    "\n",
    "    # NLP tasks\n",
    "    \"text-summarization\",\n",
    "    \"topic-modeling\",\n",
    "    \"question-answering\",\n",
    "    \"machine-translation\",\n",
    "    \"language-detection\",\n",
    "    \"dependency-parsing\",\n",
    "    \"coreference-resolution\",\n",
    "    \"entity-linking\",\n",
    "    \"word-sense-disambiguation\",\n",
    "\n",
    "    # Modern NLP concepts\n",
    "    \"llm\",\n",
    "    \"large-language-models\",\n",
    "    \"fine-tuning\",\n",
    "    \"prompt-engineering\",\n",
    "    \"zero-shot-learning\",\n",
    "    \"few-shot-learning\",\n",
    "    \"transfer-learning\",\n",
    "\n",
    "    # Applications\n",
    "    \"chatbot\",\n",
    "    \"dialogue-systems\",\n",
    "    \"text-generation\",\n",
    "    \"speech-recognition\",\n",
    "    \"speech-to-text\",\n",
    "    \"text-to-speech\",\n",
    "    \"opencv-text\",\n",
    "    \"elasticsearch\",\n",
    "    \"lucene\",\n",
    "    \"langchain\",\n",
    "    \"rnn\",\n",
    "    \"lstm\",\n",
    "    \"gru\",\n",
    "    \"bert\",\n",
    "    \"gpt\",\n",
    "    \"gpt-2\",\n",
    "    \"gpt-3\",\n",
    "    \"spacy-transformers\",\n",
    "    \"pytorch-nlp\",\n",
    "    \"tensorflow-text\",\n",
    "    \"keras-nlp\",\n",
    "    \"rasa\",\n",
    "    \"chatgpt-api\",\n",
    "    \"llama\",\n",
    "    \"openai-whisper\",\n",
    "    \"word-count\",\n",
    "    \"string-matching\",\n",
    "    \"document-understanding\",\n",
    "    \"ngram\",\n",
    "    \"keyword-extraction\",\n",
    "    \"entity-extraction\",\n",
    "    \"fuzzy-matching\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0de2e0",
   "metadata": {},
   "source": [
    "* In order to speed up data collection, we decided to devide the work within our group.\n",
    "* Each group member querying for different timeline and then we compiled everything into 1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c76ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to UNIX timestamps\n",
    "def to_unix_timestamp(date_str):\n",
    "    dt = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "    return int(dt.timestamp())\n",
    "\n",
    "# Convert Unix timestamp to readable format\n",
    "def from_unix_timestamp(timestamp):\n",
    "    return datetime.fromtimestamp(timestamp).strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604b313",
   "metadata": {},
   "source": [
    "### We decided to process only the posts which have atlease 1 accepted answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a24cf7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_posts(tag, page, start_date, end_date, request_count):\n",
    "    try:\n",
    "        base_url = \"https://api.stackexchange.com/2.3/questions\"\n",
    "        params = {\n",
    "            \"site\": \"stackoverflow\",\n",
    "            \"tagged\": tag,\n",
    "            \"filter\": \"withbody\",\n",
    "            \"pagesize\": 100,\n",
    "            \"fromdate\": start_date,\n",
    "            \"todate\": end_date,\n",
    "            \"sort\": \"creation\",\n",
    "            \"order\": \"asc\",\n",
    "            \"key\": API_KEY,\n",
    "            \"page\": page\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "        request_count += 1\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return data.get(\"items\", []), data.get(\"has_more\", False), request_count\n",
    "\n",
    "        if response.status_code == 429:  # Too Many Requests\n",
    "            backoff_time = int(response.headers.get('Backoff', 30))\n",
    "            print(f\"Rate limited. Backing off for {backoff_time} seconds\")\n",
    "            time.sleep(backoff_time)\n",
    "            # Retry the request\n",
    "            return fetch_posts(tag, page, start_date, end_date, request_count) \n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None, False, request_count\n",
    "    \n",
    "def fetch_answer(answer_id, request_count):\n",
    "    try:\n",
    "        answer_url = f\"https://api.stackexchange.com/2.3/answers/{answer_id}\"\n",
    "        answer_params = {\"site\": \"stackoverflow\", \"filter\": \"withbody\", \"key\": API_KEY}\n",
    "        response = requests.get(answer_url, params=answer_params)\n",
    "        request_count += 1\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return response.json()[\"items\"][0][\"body\"], request_count\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None, request_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43ee0ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample usage\n",
    "question_1 =fetch_posts(\"nlp\", 1, to_unix_timestamp(\"2023-01-01\"), to_unix_timestamp(\"2023-10-01\"), 0)\n",
    "answer_1 = fetch_answer(75096054, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c50f3e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question Title: snscrape error - twitter scrape crashes after a long time giving &#39;215&#39; error\n",
      "Question Body: <p>I got the following error:</p>\n",
      "<blockquote>\n",
      "<p><a href=\"https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&amp;include_blocking=1&amp;include_blocked_by=1&amp;include_followed_by=1&amp;include_want_retweets=1&amp;include_mute_edge=1&amp;include_can_dm=1&amp;include_can_media_tag=1&amp;skip_status=1&amp;cards_platform=Web-12&amp;include_cards=1&amp;include_ext_alt_text=true&amp;include_quote_count=true&amp;include_reply_count=1&amp;tweet_mode=extended&amp;include_entities=true&amp;include_user_entities=true&amp;include_ext_media_color=true&amp;include_ext_media_availability=true&amp;send_error_codes=true&amp;simple_quoted_tweets=true&amp;q=from%3Ainfobae+since%3A2018-01-01+until%3A2018-12-31&amp;tweet_search_mode=live&amp;count=100&amp;query_source=spelling_expansion_revert_click&amp;cursor=scroll%3AthGAVUV0VFVBaCgLWNpcPlwx0WgICrnczcn_sdEnEV8PFqFYCJehgHREVGQVVMVDUBFdoJFQAA&amp;pc=1&amp;spelling_corrections=1&amp;ext=mediaStats%2ChighlightedLabel\" rel=\"nofollow noreferrer\">https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&amp;include_blocking=1&amp;include_blocked_by=1&amp;include_followed_by=1&amp;include_want_retweets=1&amp;include_mute_edge=1&amp;include_can_dm=1&amp;include_can_media_tag=1&amp;skip_status=1&amp;cards_platform=Web-12&amp;include_cards=1&amp;include_ext_alt_text=true&amp;include_quote_count=true&amp;include_reply_count=1&amp;tweet_mode=extended&amp;include_entities=true&amp;include_user_entities=true&amp;include_ext_media_color=true&amp;include_ext_media_availability=true&amp;send_error_codes=true&amp;simple_quoted_tweets=true&amp;q=from%3Ainfobae+since%3A2018-01-01+until%3A2018-12-31&amp;tweet_search_mode=live&amp;count=100&amp;query_source=spelling_expansion_revert_click&amp;cursor=scroll%3AthGAVUV0VFVBaCgLWNpcPlwx0WgICrnczcn_sdEnEV8PFqFYCJehgHREVGQVVMVDUBFdoJFQAA&amp;pc=1&amp;spelling_corrections=1&amp;ext=mediaStats%2ChighlightedLabel</a></p>\n",
      "</blockquote>\n",
      "<blockquote>\n",
      "<p>snscrape.base:4 requests to <a href=\"https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&amp;include_blocking=1&amp;include_blocked_by=1&amp;include_followed_by=1&amp;include_want_retweets=1&amp;include_mute_edge=1&amp;include_can_dm=1&amp;include_can_media_tag=1&amp;skip_status=1&amp;cards_platform=Web-12&amp;include_cards=1&amp;include_ext_alt_text=true&amp;include_quote_count=true&amp;include_reply_count=1&amp;tweet_mode=extended&amp;include_entities=true&amp;include_user_entities=true&amp;include_ext_media_color=true&amp;include_ext_media_availability=true&amp;send_error_codes=true&amp;simple_quoted_tweets=true&amp;q=from%3Ainfobae+since%3A2018-01-01+until%3A2018-12-31&amp;tweet_search_mode=live&amp;count=100&amp;query_source=spelling_expansion_revert_click&amp;cursor=scroll%3AthGAVUV0VFVBaCgLWNpcPlwx0WgICrnczcn_sdEnEV8PFqFYCJehgHREVGQVVMVDUBFdoJFQAA&amp;pc=1&amp;spelling_corrections=1&amp;ext=mediaStats%2ChighlightedLabel\" rel=\"nofollow noreferrer\">https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&amp;include_blocking=1&amp;include_blocked_by=1&amp;include_followed_by=1&amp;include_want_retweets=1&amp;include_mute_edge=1&amp;include_can_dm=1&amp;include_can_media_tag=1&amp;skip_status=1&amp;cards_platform=Web-12&amp;include_cards=1&amp;include_ext_alt_text=true&amp;include_quote_count=true&amp;include_reply_count=1&amp;tweet_mode=extended&amp;include_entities=true&amp;include_user_entities=true&amp;include_ext_media_color=true&amp;include_ext_media_availability=true&amp;send_error_codes=true&amp;simple_quoted_tweets=true&amp;q=from%3Ainfobae+since%3A2018-01-01+until%3A2018-12-31&amp;tweet_search_mode=live&amp;count=100&amp;query_source=spelling_expansion_revert_click&amp;cursor=scroll%3AthGAVUV0VFVBaCgLWNpcPlwx0WgICrnczcn_sdEnEV8PFqFYCJehgHREVGQVVMVDUBFdoJFQAA&amp;pc=1&amp;spelling_corrections=1&amp;ext=mediaStats%2ChighlightedLabel</a></p>\n",
      "</blockquote>\n",
      "<p>I used this code:</p>\n",
      "<pre class=\"lang-py prettyprint-override\"><code>import snscrape.modules.twitter as sntwitter\n",
      "import pandas as pd\n",
      "import re\n",
      "\n",
      "# Setting variables to be used below\n",
      "maxTweets = 350000\n",
      "\n",
      "# Creating list to append tweet data to\n",
      "tweets_list1 = []\n",
      "user_list = ['lanacionmas','LANACION','Ambitocom','infobae','clarincom']\n",
      "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
      "for user in user_list:\n",
      "  for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:' + user +' since:2018-01-01 until:2018-12-31').get_items()):\n",
      "    if i&gt;maxTweets:\n",
      "        break\n",
      "\n",
      "    tweets_list1.append([tweet.date, tweet.id, tweet.content])\n",
      "\n",
      "print('Done' + user)\n",
      "\n",
      "</code></pre>\n",
      "<p>Do you know how to fix this error?</p>\n",
      "<p>Thanks a lot!</p>\n",
      "\n",
      "Answer: <p>Feel like your lucky day, because I created an account here just to reply to you.</p>\n",
      "<p>In in this <a href=\"https://github.com/JustAnotherArchivist/snscrape/issues/634\" rel=\"nofollow noreferrer\">issue</a>, the module creator explains what happened and how to solve the problem, but you just need add <code>top=True</code> in commands that have Twitter**Scraper, or if you are using it from the command line, use the flag <code>--top</code></p>\n",
      "<p>(I just found out that I could have posted as a guest)</p>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Question Title: {question_1[0][0]['title']}\n",
    "Question Body: {question_1[0][0]['body']}\n",
    "Answer: {answer_1[0]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "42324b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "OUTPUT_DIR = \"nlp_stackoverflow_data\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Function to save checkpoint\n",
    "def save_checkpoint(posts, tag, checkpoint_number):\n",
    "    filename = f\"{OUTPUT_DIR}/nlp_stackoverflow_{tag}_{checkpoint_number}.csv\"\n",
    "    if posts:\n",
    "        df = pd.DataFrame(posts)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Checkpoint saved: {len(posts)} posts written to {filename}\")\n",
    "    else:\n",
    "        print(f\"No posts to save for tag {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "249f3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tag(tag, start_date, end_date):\n",
    "    request_count = 0\n",
    "    page = 1\n",
    "    all_posts = []\n",
    "    has_more = True\n",
    "    max_pages = 100 # We Limit to 100 pages to avoid excessive API calls\n",
    "    checkpoint_interval = 5 # Checkpoint every 5 pages\n",
    "\n",
    "    while page <= max_pages and request_count < 10000:\n",
    "        posts, has_more, request_count = fetch_posts(tag, page, start_date, end_date, request_count)\n",
    "        if posts is not None:\n",
    "            for post in posts:\n",
    "                accepted_answer_id = post.get(\"accepted_answer_id\")\n",
    "                if not accepted_answer_id:\n",
    "                    continue\n",
    "\n",
    "                accepted_answer, request_count = fetch_answer(accepted_answer_id, request_count)\n",
    "                if accepted_answer and request_count < 10000:\n",
    "                    # Convert Unix timestamp to readable date format\n",
    "                    creation_date_readable = from_unix_timestamp(post[\"creation_date\"])\n",
    "\n",
    "                    # Store original tag the post was found with\n",
    "                    post_tags = post.get(\"tags\", [])\n",
    "\n",
    "                    all_posts.append({\n",
    "                        \"title\": post[\"title\"],\n",
    "                        \"description\": post[\"body\"],\n",
    "                        \"tags\": \";\".join(post_tags),\n",
    "                        \"source_tag\": tag,  # Tag used to fetch this post\n",
    "                        \"question_id\": post[\"question_id\"],\n",
    "                        \"view_count\": post.get(\"view_count\", 0),\n",
    "                        \"creation_date\": creation_date_readable,\n",
    "                        \"creation_timestamp\": post[\"creation_date\"],\n",
    "                        \"accepted_answer\": accepted_answer\n",
    "                    })\n",
    "\n",
    "            # Checkpoint every few pages\n",
    "            if page % checkpoint_interval == 0:\n",
    "                save_checkpoint(all_posts, tag, page)\n",
    "\n",
    "            # Sleep to respect rate limits\n",
    "            time.sleep(2)  # Conservative delay between pages\n",
    "            page += 1\n",
    "\n",
    "            if not has_more:\n",
    "                print(f\"No more pages available for tag {tag}.\")\n",
    "                break\n",
    "\n",
    "    # Final save for this tag\n",
    "    save_checkpoint(all_posts, tag, \"final\")\n",
    "    print(f\"Completed processing tag {tag}! Downloaded {len(all_posts)} posts with accepted answers.\")\n",
    "    return all_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e394b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    start_date = to_unix_timestamp(\"2023-01-01\")\n",
    "    end_date = to_unix_timestamp(\"2023-02-01\")\n",
    "    for tag in tags_to_fetch:\n",
    "        print(f\"******************************************************\")\n",
    "        print(f\"Processing tag: {tag}\")\n",
    "        all_posts = process_tag(tag, start_date, end_date)\n",
    "        print(f\"Total posts fetched for tag {tag}: {len(all_posts)}\")\n",
    "        print(f\"******************************************************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26b06952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************\n",
      "Processing tag: nlp\n",
      "No more pages available for tag nlp.\n",
      "Checkpoint saved: 44 posts written to nlp_stackoverflow_data/nlp_stackoverflow_nlp_final.csv\n",
      "Completed processing tag nlp! Downloaded 44 posts with accepted answers.\n",
      "Total posts fetched for tag nlp: 44\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: natural-language-processing\n",
      "No more pages available for tag natural-language-processing.\n",
      "Checkpoint saved: 44 posts written to nlp_stackoverflow_data/nlp_stackoverflow_natural-language-processing_final.csv\n",
      "Completed processing tag natural-language-processing! Downloaded 44 posts with accepted answers.\n",
      "Total posts fetched for tag natural-language-processing: 44\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: computational-linguistics\n",
      "No more pages available for tag computational-linguistics.\n",
      "Checkpoint saved: 44 posts written to nlp_stackoverflow_data/nlp_stackoverflow_computational-linguistics_final.csv\n",
      "Completed processing tag computational-linguistics! Downloaded 44 posts with accepted answers.\n",
      "Total posts fetched for tag computational-linguistics: 44\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: text-classification\n",
      "No more pages available for tag text-classification.\n",
      "Checkpoint saved: 5 posts written to nlp_stackoverflow_data/nlp_stackoverflow_text-classification_final.csv\n",
      "Completed processing tag text-classification! Downloaded 5 posts with accepted answers.\n",
      "Total posts fetched for tag text-classification: 5\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: document-classification\n",
      "No more pages available for tag document-classification.\n",
      "No posts to save for tag document-classification\n",
      "Completed processing tag document-classification! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag document-classification: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: sentiment-analysis\n",
      "No more pages available for tag sentiment-analysis.\n",
      "Checkpoint saved: 3 posts written to nlp_stackoverflow_data/nlp_stackoverflow_sentiment-analysis_final.csv\n",
      "Completed processing tag sentiment-analysis! Downloaded 3 posts with accepted answers.\n",
      "Total posts fetched for tag sentiment-analysis: 3\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: emotion-detection\n",
      "No more pages available for tag emotion-detection.\n",
      "No posts to save for tag emotion-detection\n",
      "Completed processing tag emotion-detection! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag emotion-detection: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: text-mining\n",
      "No more pages available for tag text-mining.\n",
      "Checkpoint saved: 5 posts written to nlp_stackoverflow_data/nlp_stackoverflow_text-mining_final.csv\n",
      "Completed processing tag text-mining! Downloaded 5 posts with accepted answers.\n",
      "Total posts fetched for tag text-mining: 5\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: text-analytics\n",
      "No more pages available for tag text-analytics.\n",
      "No posts to save for tag text-analytics\n",
      "Completed processing tag text-analytics! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag text-analytics: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: tokenization\n",
      "No more pages available for tag tokenization.\n",
      "Checkpoint saved: 4 posts written to nlp_stackoverflow_data/nlp_stackoverflow_tokenization_final.csv\n",
      "Completed processing tag tokenization! Downloaded 4 posts with accepted answers.\n",
      "Total posts fetched for tag tokenization: 4\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: named-entity-recognition\n",
      "No more pages available for tag named-entity-recognition.\n",
      "Checkpoint saved: 4 posts written to nlp_stackoverflow_data/nlp_stackoverflow_named-entity-recognition_final.csv\n",
      "Completed processing tag named-entity-recognition! Downloaded 4 posts with accepted answers.\n",
      "Total posts fetched for tag named-entity-recognition: 4\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: ner\n",
      "No more pages available for tag ner.\n",
      "Checkpoint saved: 4 posts written to nlp_stackoverflow_data/nlp_stackoverflow_ner_final.csv\n",
      "Completed processing tag ner! Downloaded 4 posts with accepted answers.\n",
      "Total posts fetched for tag ner: 4\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: pos-tagging\n",
      "No more pages available for tag pos-tagging.\n",
      "No posts to save for tag pos-tagging\n",
      "Completed processing tag pos-tagging! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag pos-tagging: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: part-of-speech\n",
      "No more pages available for tag part-of-speech.\n",
      "Checkpoint saved: 2 posts written to nlp_stackoverflow_data/nlp_stackoverflow_part-of-speech_final.csv\n",
      "Completed processing tag part-of-speech! Downloaded 2 posts with accepted answers.\n",
      "Total posts fetched for tag part-of-speech: 2\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: lemmatization\n",
      "No more pages available for tag lemmatization.\n",
      "Checkpoint saved: 1 posts written to nlp_stackoverflow_data/nlp_stackoverflow_lemmatization_final.csv\n",
      "Completed processing tag lemmatization! Downloaded 1 posts with accepted answers.\n",
      "Total posts fetched for tag lemmatization: 1\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: stemming\n",
      "No more pages available for tag stemming.\n",
      "No posts to save for tag stemming\n",
      "Completed processing tag stemming! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag stemming: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: stopwords\n",
      "No more pages available for tag stopwords.\n",
      "No posts to save for tag stopwords\n",
      "Completed processing tag stopwords! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag stopwords: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: text-preprocessing\n",
      "No more pages available for tag text-preprocessing.\n",
      "No posts to save for tag text-preprocessing\n",
      "Completed processing tag text-preprocessing! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag text-preprocessing: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: text-normalization\n",
      "No more pages available for tag text-normalization.\n",
      "No posts to save for tag text-normalization\n",
      "Completed processing tag text-normalization! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag text-normalization: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: spacy\n",
      "No more pages available for tag spacy.\n",
      "Checkpoint saved: 8 posts written to nlp_stackoverflow_data/nlp_stackoverflow_spacy_final.csv\n",
      "Completed processing tag spacy! Downloaded 8 posts with accepted answers.\n",
      "Total posts fetched for tag spacy: 8\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: nltk\n",
      "No more pages available for tag nltk.\n",
      "Checkpoint saved: 6 posts written to nlp_stackoverflow_data/nlp_stackoverflow_nltk_final.csv\n",
      "Completed processing tag nltk! Downloaded 6 posts with accepted answers.\n",
      "Total posts fetched for tag nltk: 6\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: gensim\n",
      "No more pages available for tag gensim.\n",
      "Checkpoint saved: 7 posts written to nlp_stackoverflow_data/nlp_stackoverflow_gensim_final.csv\n",
      "Completed processing tag gensim! Downloaded 7 posts with accepted answers.\n",
      "Total posts fetched for tag gensim: 7\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: huggingface\n",
      "No more pages available for tag huggingface.\n",
      "Checkpoint saved: 8 posts written to nlp_stackoverflow_data/nlp_stackoverflow_huggingface_final.csv\n",
      "Completed processing tag huggingface! Downloaded 8 posts with accepted answers.\n",
      "Total posts fetched for tag huggingface: 8\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: transformers\n",
      "No more pages available for tag transformers.\n",
      "No posts to save for tag transformers\n",
      "Completed processing tag transformers! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag transformers: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: corenlp\n",
      "No more pages available for tag corenlp.\n",
      "Checkpoint saved: 1 posts written to nlp_stackoverflow_data/nlp_stackoverflow_corenlp_final.csv\n",
      "Completed processing tag corenlp! Downloaded 1 posts with accepted answers.\n",
      "Total posts fetched for tag corenlp: 1\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: stanza\n",
      "No more pages available for tag stanza.\n",
      "Checkpoint saved: 1 posts written to nlp_stackoverflow_data/nlp_stackoverflow_stanza_final.csv\n",
      "Completed processing tag stanza! Downloaded 1 posts with accepted answers.\n",
      "Total posts fetched for tag stanza: 1\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: flair\n",
      "No more pages available for tag flair.\n",
      "No posts to save for tag flair\n",
      "Completed processing tag flair! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag flair: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: allennlp\n",
      "No more pages available for tag allennlp.\n",
      "No posts to save for tag allennlp\n",
      "Completed processing tag allennlp! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag allennlp: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: bert\n",
      "No more pages available for tag bert.\n",
      "Checkpoint saved: 9 posts written to nlp_stackoverflow_data/nlp_stackoverflow_bert_final.csv\n",
      "Completed processing tag bert! Downloaded 9 posts with accepted answers.\n",
      "Total posts fetched for tag bert: 9\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: roberta\n",
      "No more pages available for tag roberta.\n",
      "Checkpoint saved: 1 posts written to nlp_stackoverflow_data/nlp_stackoverflow_roberta_final.csv\n",
      "Completed processing tag roberta! Downloaded 1 posts with accepted answers.\n",
      "Total posts fetched for tag roberta: 1\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: gpt\n",
      "No more pages available for tag gpt.\n",
      "Checkpoint saved: 1 posts written to nlp_stackoverflow_data/nlp_stackoverflow_gpt_final.csv\n",
      "Completed processing tag gpt! Downloaded 1 posts with accepted answers.\n",
      "Total posts fetched for tag gpt: 1\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: language-model\n",
      "No more pages available for tag language-model.\n",
      "No posts to save for tag language-model\n",
      "Completed processing tag language-model! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag language-model: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: word2vec\n",
      "No more pages available for tag word2vec.\n",
      "Checkpoint saved: 4 posts written to nlp_stackoverflow_data/nlp_stackoverflow_word2vec_final.csv\n",
      "Completed processing tag word2vec! Downloaded 4 posts with accepted answers.\n",
      "Total posts fetched for tag word2vec: 4\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: glove\n",
      "No more pages available for tag glove.\n",
      "Checkpoint saved: 1 posts written to nlp_stackoverflow_data/nlp_stackoverflow_glove_final.csv\n",
      "Completed processing tag glove! Downloaded 1 posts with accepted answers.\n",
      "Total posts fetched for tag glove: 1\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: fasttext\n",
      "No more pages available for tag fasttext.\n",
      "No posts to save for tag fasttext\n",
      "Completed processing tag fasttext! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag fasttext: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: word-embeddings\n",
      "No more pages available for tag word-embeddings.\n",
      "No posts to save for tag word-embeddings\n",
      "Completed processing tag word-embeddings! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag word-embeddings: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: sentence-embeddings\n",
      "No more pages available for tag sentence-embeddings.\n",
      "No posts to save for tag sentence-embeddings\n",
      "Completed processing tag sentence-embeddings! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag sentence-embeddings: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: contextual-embeddings\n",
      "No more pages available for tag contextual-embeddings.\n",
      "No posts to save for tag contextual-embeddings\n",
      "Completed processing tag contextual-embeddings! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag contextual-embeddings: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: tfidf\n",
      "No more pages available for tag tfidf.\n",
      "No posts to save for tag tfidf\n",
      "Completed processing tag tfidf! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag tfidf: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: information-retrieval\n",
      "No more pages available for tag information-retrieval.\n",
      "No posts to save for tag information-retrieval\n",
      "Completed processing tag information-retrieval! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag information-retrieval: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: semantic-search\n",
      "No more pages available for tag semantic-search.\n",
      "No posts to save for tag semantic-search\n",
      "Completed processing tag semantic-search! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag semantic-search: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: document-similarity\n",
      "No more pages available for tag document-similarity.\n",
      "No posts to save for tag document-similarity\n",
      "Completed processing tag document-similarity! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag document-similarity: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: text-similarity\n",
      "No more pages available for tag text-similarity.\n",
      "No posts to save for tag text-similarity\n",
      "Completed processing tag text-similarity! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag text-similarity: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: cosine-similarity\n",
      "No more pages available for tag cosine-similarity.\n",
      "Checkpoint saved: 2 posts written to nlp_stackoverflow_data/nlp_stackoverflow_cosine-similarity_final.csv\n",
      "Completed processing tag cosine-similarity! Downloaded 2 posts with accepted answers.\n",
      "Total posts fetched for tag cosine-similarity: 2\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: text-summarization\n",
      "No more pages available for tag text-summarization.\n",
      "No posts to save for tag text-summarization\n",
      "Completed processing tag text-summarization! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag text-summarization: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: topic-modeling\n",
      "No more pages available for tag topic-modeling.\n",
      "Checkpoint saved: 4 posts written to nlp_stackoverflow_data/nlp_stackoverflow_topic-modeling_final.csv\n",
      "Completed processing tag topic-modeling! Downloaded 4 posts with accepted answers.\n",
      "Total posts fetched for tag topic-modeling: 4\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: question-answering\n",
      "No more pages available for tag question-answering.\n",
      "No posts to save for tag question-answering\n",
      "Completed processing tag question-answering! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag question-answering: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: machine-translation\n",
      "No more pages available for tag machine-translation.\n",
      "Checkpoint saved: 1 posts written to nlp_stackoverflow_data/nlp_stackoverflow_machine-translation_final.csv\n",
      "Completed processing tag machine-translation! Downloaded 1 posts with accepted answers.\n",
      "Total posts fetched for tag machine-translation: 1\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: language-detection\n",
      "No more pages available for tag language-detection.\n",
      "Checkpoint saved: 1 posts written to nlp_stackoverflow_data/nlp_stackoverflow_language-detection_final.csv\n",
      "Completed processing tag language-detection! Downloaded 1 posts with accepted answers.\n",
      "Total posts fetched for tag language-detection: 1\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: dependency-parsing\n",
      "No more pages available for tag dependency-parsing.\n",
      "No posts to save for tag dependency-parsing\n",
      "Completed processing tag dependency-parsing! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag dependency-parsing: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: coreference-resolution\n",
      "No more pages available for tag coreference-resolution.\n",
      "No posts to save for tag coreference-resolution\n",
      "Completed processing tag coreference-resolution! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag coreference-resolution: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: entity-linking\n",
      "No more pages available for tag entity-linking.\n",
      "No posts to save for tag entity-linking\n",
      "Completed processing tag entity-linking! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag entity-linking: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: word-sense-disambiguation\n",
      "No more pages available for tag word-sense-disambiguation.\n",
      "No posts to save for tag word-sense-disambiguation\n",
      "Completed processing tag word-sense-disambiguation! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag word-sense-disambiguation: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: llm\n",
      "No more pages available for tag llm.\n",
      "No posts to save for tag llm\n",
      "Completed processing tag llm! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag llm: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: large-language-models\n",
      "No more pages available for tag large-language-models.\n",
      "No posts to save for tag large-language-models\n",
      "Completed processing tag large-language-models! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag large-language-models: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: fine-tuning\n",
      "No more pages available for tag fine-tuning.\n",
      "Checkpoint saved: 1 posts written to nlp_stackoverflow_data/nlp_stackoverflow_fine-tuning_final.csv\n",
      "Completed processing tag fine-tuning! Downloaded 1 posts with accepted answers.\n",
      "Total posts fetched for tag fine-tuning: 1\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: prompt-engineering\n",
      "No more pages available for tag prompt-engineering.\n",
      "No posts to save for tag prompt-engineering\n",
      "Completed processing tag prompt-engineering! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag prompt-engineering: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: zero-shot-learning\n",
      "No more pages available for tag zero-shot-learning.\n",
      "No posts to save for tag zero-shot-learning\n",
      "Completed processing tag zero-shot-learning! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag zero-shot-learning: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: few-shot-learning\n",
      "No more pages available for tag few-shot-learning.\n",
      "No posts to save for tag few-shot-learning\n",
      "Completed processing tag few-shot-learning! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag few-shot-learning: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: transfer-learning\n",
      "No more pages available for tag transfer-learning.\n",
      "Checkpoint saved: 3 posts written to nlp_stackoverflow_data/nlp_stackoverflow_transfer-learning_final.csv\n",
      "Completed processing tag transfer-learning! Downloaded 3 posts with accepted answers.\n",
      "Total posts fetched for tag transfer-learning: 3\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: chatbot\n",
      "No more pages available for tag chatbot.\n",
      "Checkpoint saved: 4 posts written to nlp_stackoverflow_data/nlp_stackoverflow_chatbot_final.csv\n",
      "Completed processing tag chatbot! Downloaded 4 posts with accepted answers.\n",
      "Total posts fetched for tag chatbot: 4\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: dialogue-systems\n",
      "No more pages available for tag dialogue-systems.\n",
      "No posts to save for tag dialogue-systems\n",
      "Completed processing tag dialogue-systems! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag dialogue-systems: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: text-generation\n",
      "No more pages available for tag text-generation.\n",
      "No posts to save for tag text-generation\n",
      "Completed processing tag text-generation! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag text-generation: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: speech-recognition\n",
      "No more pages available for tag speech-recognition.\n",
      "Checkpoint saved: 7 posts written to nlp_stackoverflow_data/nlp_stackoverflow_speech-recognition_final.csv\n",
      "Completed processing tag speech-recognition! Downloaded 7 posts with accepted answers.\n",
      "Total posts fetched for tag speech-recognition: 7\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: speech-to-text\n",
      "No more pages available for tag speech-to-text.\n",
      "Checkpoint saved: 4 posts written to nlp_stackoverflow_data/nlp_stackoverflow_speech-to-text_final.csv\n",
      "Completed processing tag speech-to-text! Downloaded 4 posts with accepted answers.\n",
      "Total posts fetched for tag speech-to-text: 4\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: text-to-speech\n",
      "No more pages available for tag text-to-speech.\n",
      "Checkpoint saved: 4 posts written to nlp_stackoverflow_data/nlp_stackoverflow_text-to-speech_final.csv\n",
      "Completed processing tag text-to-speech! Downloaded 4 posts with accepted answers.\n",
      "Total posts fetched for tag text-to-speech: 4\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: opencv-text\n",
      "No more pages available for tag opencv-text.\n",
      "No posts to save for tag opencv-text\n",
      "Completed processing tag opencv-text! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag opencv-text: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: elasticsearch\n",
      "No more pages available for tag elasticsearch.\n",
      "Checkpoint saved: 97 posts written to nlp_stackoverflow_data/nlp_stackoverflow_elasticsearch_final.csv\n",
      "Completed processing tag elasticsearch! Downloaded 97 posts with accepted answers.\n",
      "Total posts fetched for tag elasticsearch: 97\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: lucene\n",
      "No more pages available for tag lucene.\n",
      "No posts to save for tag lucene\n",
      "Completed processing tag lucene! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag lucene: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: langchain\n",
      "No more pages available for tag langchain.\n",
      "No posts to save for tag langchain\n",
      "Completed processing tag langchain! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag langchain: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: rnn\n",
      "No more pages available for tag rnn.\n",
      "Checkpoint saved: 2 posts written to nlp_stackoverflow_data/nlp_stackoverflow_rnn_final.csv\n",
      "Completed processing tag rnn! Downloaded 2 posts with accepted answers.\n",
      "Total posts fetched for tag rnn: 2\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: lstm\n",
      "No more pages available for tag lstm.\n",
      "Checkpoint saved: 7 posts written to nlp_stackoverflow_data/nlp_stackoverflow_lstm_final.csv\n",
      "Completed processing tag lstm! Downloaded 7 posts with accepted answers.\n",
      "Total posts fetched for tag lstm: 7\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: gru\n",
      "No more pages available for tag gru.\n",
      "No posts to save for tag gru\n",
      "Completed processing tag gru! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag gru: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: bert\n",
      "No more pages available for tag bert.\n",
      "Checkpoint saved: 9 posts written to nlp_stackoverflow_data/nlp_stackoverflow_bert_final.csv\n",
      "Completed processing tag bert! Downloaded 9 posts with accepted answers.\n",
      "Total posts fetched for tag bert: 9\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: gpt\n",
      "No more pages available for tag gpt.\n",
      "Checkpoint saved: 1 posts written to nlp_stackoverflow_data/nlp_stackoverflow_gpt_final.csv\n",
      "Completed processing tag gpt! Downloaded 1 posts with accepted answers.\n",
      "Total posts fetched for tag gpt: 1\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: gpt-2\n",
      "No more pages available for tag gpt-2.\n",
      "Checkpoint saved: 3 posts written to nlp_stackoverflow_data/nlp_stackoverflow_gpt-2_final.csv\n",
      "Completed processing tag gpt-2! Downloaded 3 posts with accepted answers.\n",
      "Total posts fetched for tag gpt-2: 3\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: gpt-3\n",
      "No more pages available for tag gpt-3.\n",
      "Checkpoint saved: 9 posts written to nlp_stackoverflow_data/nlp_stackoverflow_gpt-3_final.csv\n",
      "Completed processing tag gpt-3! Downloaded 9 posts with accepted answers.\n",
      "Total posts fetched for tag gpt-3: 9\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: spacy-transformers\n",
      "No more pages available for tag spacy-transformers.\n",
      "No posts to save for tag spacy-transformers\n",
      "Completed processing tag spacy-transformers! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag spacy-transformers: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: pytorch-nlp\n",
      "No more pages available for tag pytorch-nlp.\n",
      "No posts to save for tag pytorch-nlp\n",
      "Completed processing tag pytorch-nlp! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag pytorch-nlp: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: tensorflow-text\n",
      "No more pages available for tag tensorflow-text.\n",
      "No posts to save for tag tensorflow-text\n",
      "Completed processing tag tensorflow-text! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag tensorflow-text: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: keras-nlp\n",
      "No more pages available for tag keras-nlp.\n",
      "No posts to save for tag keras-nlp\n",
      "Completed processing tag keras-nlp! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag keras-nlp: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: rasa\n",
      "No more pages available for tag rasa.\n",
      "Checkpoint saved: 2 posts written to nlp_stackoverflow_data/nlp_stackoverflow_rasa_final.csv\n",
      "Completed processing tag rasa! Downloaded 2 posts with accepted answers.\n",
      "Total posts fetched for tag rasa: 2\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: chatgpt-api\n",
      "No more pages available for tag chatgpt-api.\n",
      "No posts to save for tag chatgpt-api\n",
      "Completed processing tag chatgpt-api! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag chatgpt-api: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: llama\n",
      "No more pages available for tag llama.\n",
      "No posts to save for tag llama\n",
      "Completed processing tag llama! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag llama: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: openai-whisper\n",
      "No more pages available for tag openai-whisper.\n",
      "Checkpoint saved: 1 posts written to nlp_stackoverflow_data/nlp_stackoverflow_openai-whisper_final.csv\n",
      "Completed processing tag openai-whisper! Downloaded 1 posts with accepted answers.\n",
      "Total posts fetched for tag openai-whisper: 1\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: word-count\n",
      "No more pages available for tag word-count.\n",
      "No posts to save for tag word-count\n",
      "Completed processing tag word-count! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag word-count: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: string-matching\n",
      "No more pages available for tag string-matching.\n",
      "Checkpoint saved: 5 posts written to nlp_stackoverflow_data/nlp_stackoverflow_string-matching_final.csv\n",
      "Completed processing tag string-matching! Downloaded 5 posts with accepted answers.\n",
      "Total posts fetched for tag string-matching: 5\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: document-understanding\n",
      "No more pages available for tag document-understanding.\n",
      "No posts to save for tag document-understanding\n",
      "Completed processing tag document-understanding! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag document-understanding: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: ngram\n",
      "No more pages available for tag ngram.\n",
      "No posts to save for tag ngram\n",
      "Completed processing tag ngram! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag ngram: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: keyword-extraction\n",
      "No more pages available for tag keyword-extraction.\n",
      "Checkpoint saved: 1 posts written to nlp_stackoverflow_data/nlp_stackoverflow_keyword-extraction_final.csv\n",
      "Completed processing tag keyword-extraction! Downloaded 1 posts with accepted answers.\n",
      "Total posts fetched for tag keyword-extraction: 1\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: entity-extraction\n",
      "No more pages available for tag entity-extraction.\n",
      "No posts to save for tag entity-extraction\n",
      "Completed processing tag entity-extraction! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag entity-extraction: 0\n",
      "******************************************************\n",
      "\n",
      "******************************************************\n",
      "Processing tag: fuzzy-matching\n",
      "No more pages available for tag fuzzy-matching.\n",
      "No posts to save for tag fuzzy-matching\n",
      "Completed processing tag fuzzy-matching! Downloaded 0 posts with accepted answers.\n",
      "Total posts fetched for tag fuzzy-matching: 0\n",
      "******************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35993a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets save all the data into 1 csv file and remove duplicates and finally save as parquet\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Directory containing the CSV files\n",
    "directory = \"nlp_stackoverflow_data\"\n",
    "\n",
    "# Lets read all the csv files and combine them into a single dataframe\n",
    "all_data = pd.DataFrame()\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "# Remove duplicates based on 'question_id' and 'accepted_answer'\n",
    "all_data.drop_duplicates(subset=['question_id', 'accepted_answer'], inplace=True)\n",
    "\n",
    "# Reset index after dropping duplicates\n",
    "all_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the combined dataframe as a Parquet file\n",
    "all_data.to_parquet(\"nlp_stackoverflow_all_combined.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e40ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>source_tag</th>\n",
       "      <th>question_id</th>\n",
       "      <th>view_count</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>creation_timestamp</th>\n",
       "      <th>accepted_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do I need to retrain Bert for NER to create ne...</td>\n",
       "      <td>&lt;p&gt;I am very new to natural language processin...</td>\n",
       "      <td>nlp;bert-language-model;fine-tuning</td>\n",
       "      <td>bert</td>\n",
       "      <td>74978191</td>\n",
       "      <td>650</td>\n",
       "      <td>2023-01-02 10:52:59</td>\n",
       "      <td>1672618979</td>\n",
       "      <td>&lt;p&gt;Yes, you would have to use a model trained ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do BERT word embeddings change depending on co...</td>\n",
       "      <td>&lt;p&gt;Before answering &amp;quot;yes, of course&amp;quot;...</td>\n",
       "      <td>nlp;huggingface-transformers;bert-language-mod...</td>\n",
       "      <td>bert</td>\n",
       "      <td>74996994</td>\n",
       "      <td>1121</td>\n",
       "      <td>2023-01-04 04:28:21</td>\n",
       "      <td>1672768701</td>\n",
       "      <td>&lt;p&gt;This is a great question (I had the same qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why is positional encoding needed while input ...</td>\n",
       "      <td>&lt;p&gt;For example, in Huggingface's example:&lt;/p&gt;\\...</td>\n",
       "      <td>huggingface-transformers;bert-language-model</td>\n",
       "      <td>bert</td>\n",
       "      <td>75050748</td>\n",
       "      <td>536</td>\n",
       "      <td>2023-01-09 06:12:12</td>\n",
       "      <td>1673206932</td>\n",
       "      <td>&lt;p&gt;The reason is the design of the neural arch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Having trouble understanding the predictions a...</td>\n",
       "      <td>&lt;p&gt;I'm working on a sarcasm detector with the ...</td>\n",
       "      <td>deep-learning;bert-language-model;text-classif...</td>\n",
       "      <td>bert</td>\n",
       "      <td>75061462</td>\n",
       "      <td>63</td>\n",
       "      <td>2023-01-10 04:51:10</td>\n",
       "      <td>1673288470</td>\n",
       "      <td>&lt;p&gt;There are two values because you have two c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trouble in installing BERTopic&amp;#39;s dependenc...</td>\n",
       "      <td>&lt;p&gt;I'm trying to run the following code from t...</td>\n",
       "      <td>python;bert-language-model;topic-modeling</td>\n",
       "      <td>bert</td>\n",
       "      <td>75083854</td>\n",
       "      <td>3026</td>\n",
       "      <td>2023-01-12 00:01:47</td>\n",
       "      <td>1673443907</td>\n",
       "      <td>&lt;p&gt;I would advise starting from a completely f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>How to change the first conv layer in the resn...</td>\n",
       "      <td>&lt;p&gt;I have a data with 20 class, and I'd like t...</td>\n",
       "      <td>pytorch;transfer-learning</td>\n",
       "      <td>transfer-learning</td>\n",
       "      <td>75049663</td>\n",
       "      <td>984</td>\n",
       "      <td>2023-01-09 03:23:30</td>\n",
       "      <td>1673196810</td>\n",
       "      <td>&lt;p&gt;You can access to the layer &lt;code&gt;(conv2) i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Python ResNet50: model.save() NotImplementedError</td>\n",
       "      <td>&lt;p&gt;My goal is to save (and then load) a resent...</td>\n",
       "      <td>python;resnet;transfer-learning</td>\n",
       "      <td>transfer-learning</td>\n",
       "      <td>75132030</td>\n",
       "      <td>336</td>\n",
       "      <td>2023-01-16 19:28:59</td>\n",
       "      <td>1673859539</td>\n",
       "      <td>&lt;p&gt;The problem is with this line&lt;/p&gt;\\n&lt;pre&gt;&lt;co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>ValueError: Exception encountered when calling...</td>\n",
       "      <td>&lt;p&gt;I get this error when I try to train my mod...</td>\n",
       "      <td>tensorflow;keras;transfer-learning</td>\n",
       "      <td>transfer-learning</td>\n",
       "      <td>75205028</td>\n",
       "      <td>1159</td>\n",
       "      <td>2023-01-23 11:50:04</td>\n",
       "      <td>1674436804</td>\n",
       "      <td>&lt;p&gt;Because if you want to make transfer learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>&amp;#39;Word2Vec&amp;#39; object has no attribute &amp;#3...</td>\n",
       "      <td>&lt;p&gt;This is the version of gensim I am using:&lt;/...</td>\n",
       "      <td>python;vectorization;word2vec;word-embedding</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>75023586</td>\n",
       "      <td>562</td>\n",
       "      <td>2023-01-06 06:12:32</td>\n",
       "      <td>1672947752</td>\n",
       "      <td>&lt;p&gt;&lt;code&gt;.infer_vector()&lt;/code&gt; is only availa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Word2Vec empty word not in vocabulary</td>\n",
       "      <td>&lt;p&gt;I'm currently required to work on a multili...</td>\n",
       "      <td>python;word2vec</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>75256900</td>\n",
       "      <td>243</td>\n",
       "      <td>2023-01-27 21:04:55</td>\n",
       "      <td>1674815695</td>\n",
       "      <td>&lt;p&gt;It turns out it was because of the delimite...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Do I need to retrain Bert for NER to create ne...   \n",
       "1    Do BERT word embeddings change depending on co...   \n",
       "2    Why is positional encoding needed while input ...   \n",
       "3    Having trouble understanding the predictions a...   \n",
       "4    Trouble in installing BERTopic&#39;s dependenc...   \n",
       "..                                                 ...   \n",
       "218  How to change the first conv layer in the resn...   \n",
       "219  Python ResNet50: model.save() NotImplementedError   \n",
       "220  ValueError: Exception encountered when calling...   \n",
       "221  &#39;Word2Vec&#39; object has no attribute &#3...   \n",
       "222              Word2Vec empty word not in vocabulary   \n",
       "\n",
       "                                           description  \\\n",
       "0    <p>I am very new to natural language processin...   \n",
       "1    <p>Before answering &quot;yes, of course&quot;...   \n",
       "2    <p>For example, in Huggingface's example:</p>\\...   \n",
       "3    <p>I'm working on a sarcasm detector with the ...   \n",
       "4    <p>I'm trying to run the following code from t...   \n",
       "..                                                 ...   \n",
       "218  <p>I have a data with 20 class, and I'd like t...   \n",
       "219  <p>My goal is to save (and then load) a resent...   \n",
       "220  <p>I get this error when I try to train my mod...   \n",
       "221  <p>This is the version of gensim I am using:</...   \n",
       "222  <p>I'm currently required to work on a multili...   \n",
       "\n",
       "                                                  tags         source_tag  \\\n",
       "0                  nlp;bert-language-model;fine-tuning               bert   \n",
       "1    nlp;huggingface-transformers;bert-language-mod...               bert   \n",
       "2         huggingface-transformers;bert-language-model               bert   \n",
       "3    deep-learning;bert-language-model;text-classif...               bert   \n",
       "4            python;bert-language-model;topic-modeling               bert   \n",
       "..                                                 ...                ...   \n",
       "218                          pytorch;transfer-learning  transfer-learning   \n",
       "219                    python;resnet;transfer-learning  transfer-learning   \n",
       "220                 tensorflow;keras;transfer-learning  transfer-learning   \n",
       "221       python;vectorization;word2vec;word-embedding           word2vec   \n",
       "222                                    python;word2vec           word2vec   \n",
       "\n",
       "     question_id  view_count        creation_date  creation_timestamp  \\\n",
       "0       74978191         650  2023-01-02 10:52:59          1672618979   \n",
       "1       74996994        1121  2023-01-04 04:28:21          1672768701   \n",
       "2       75050748         536  2023-01-09 06:12:12          1673206932   \n",
       "3       75061462          63  2023-01-10 04:51:10          1673288470   \n",
       "4       75083854        3026  2023-01-12 00:01:47          1673443907   \n",
       "..           ...         ...                  ...                 ...   \n",
       "218     75049663         984  2023-01-09 03:23:30          1673196810   \n",
       "219     75132030         336  2023-01-16 19:28:59          1673859539   \n",
       "220     75205028        1159  2023-01-23 11:50:04          1674436804   \n",
       "221     75023586         562  2023-01-06 06:12:32          1672947752   \n",
       "222     75256900         243  2023-01-27 21:04:55          1674815695   \n",
       "\n",
       "                                       accepted_answer  \n",
       "0    <p>Yes, you would have to use a model trained ...  \n",
       "1    <p>This is a great question (I had the same qu...  \n",
       "2    <p>The reason is the design of the neural arch...  \n",
       "3    <p>There are two values because you have two c...  \n",
       "4    <p>I would advise starting from a completely f...  \n",
       "..                                                 ...  \n",
       "218  <p>You can access to the layer <code>(conv2) i...  \n",
       "219  <p>The problem is with this line</p>\\n<pre><co...  \n",
       "220  <p>Because if you want to make transfer learni...  \n",
       "221  <p><code>.infer_vector()</code> is only availa...  \n",
       "222  <p>It turns out it was because of the delimite...  \n",
       "\n",
       "[223 rows x 9 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Like this we combined every team member's data into a single file and removed duplicates\n",
    "# We ran it for multiple days to overcome the API limits and then combined all the data into a single file\n",
    "# Now we can use this data for our analysis and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts with accepted answers: 27783\n"
     ]
    }
   ],
   "source": [
    "# finally we were able to collect 27k+ posts with accepted answer\n",
    "df = pd.read_parquet(\"nlp_stackoverflow_all_combined.parquet\")\n",
    "print(f\"Total posts with accepted answers: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "39c65d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>accepted_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Methods for Geotagging or Geolabelling Text Co...</td>\n",
       "      <td>&lt;p&gt;What are some good algorithms for automatic...</td>\n",
       "      <td>algorithm;statistics;nlp;named-entity-recognition</td>\n",
       "      <td>&lt;p&gt;You're looking for a &lt;a href=\"https://secur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Named Entity Recognition Libraries for Java</td>\n",
       "      <td>&lt;p&gt;I am looking for a simple but \"good enough\"...</td>\n",
       "      <td>java;nlp;named-entity-recognition</td>\n",
       "      <td>&lt;p&gt;BTW, I recently ran across &lt;a href=\"http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algorithms recognizing physical address on a w...</td>\n",
       "      <td>&lt;p&gt;What are the best algorithms for recognizin...</td>\n",
       "      <td>algorithm;screen-scraping;nlp;pattern-matching...</td>\n",
       "      <td>&lt;p&gt;A named-entity extraction framework such as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Strategies for recognizing proper nouns in NLP</td>\n",
       "      <td>&lt;p&gt;I'm interested in learning more about &lt;a hr...</td>\n",
       "      <td>nlp;named-entity-recognition;part-of-speech</td>\n",
       "      <td>&lt;p&gt;The task of determining the proper part of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algorithms for named entity recognition</td>\n",
       "      <td>&lt;p&gt;I would like to use named entity recognitio...</td>\n",
       "      <td>php;python;extract;analysis;named-entity-recog...</td>\n",
       "      <td>&lt;p&gt;To start with check out &lt;a href=\"http://www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27778</th>\n",
       "      <td>Can&amp;#39;t get UUID from similarity search Weav...</td>\n",
       "      <td>&lt;p&gt;I tried to retrieve documents with similar ...</td>\n",
       "      <td>python;langchain;vector-database;weaviate</td>\n",
       "      <td>&lt;p&gt;Duda Nogueira from Weaviate here!&lt;/p&gt;\\n&lt;p&gt;C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27779</th>\n",
       "      <td>When using &amp;#39;interrupt&amp;#39; followed by &amp;#3...</td>\n",
       "      <td>&lt;p&gt;When I invoke a graph that includes &lt;code&gt;i...</td>\n",
       "      <td>javascript;langchain;langgraph</td>\n",
       "      <td>&lt;p&gt;I'm an engineer on the LangChain team, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27780</th>\n",
       "      <td>Precision used in ChromaDB Index</td>\n",
       "      <td>&lt;p&gt;I am using BAAI/bge-large-en-v1.5 model to ...</td>\n",
       "      <td>langchain;embedding;dtype;chromadb;vector-data...</td>\n",
       "      <td>&lt;p&gt;like this:&lt;/p&gt;\\n&lt;pre&gt;&lt;code&gt;import chromadb\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27781</th>\n",
       "      <td>Presidio with Langchain Experimental does not ...</td>\n",
       "      <td>&lt;p&gt;I am using presidio/langchain_experimental ...</td>\n",
       "      <td>python;nlp;spacy;langchain;presidio</td>\n",
       "      <td>&lt;p&gt;After some test I was able to find the solu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27782</th>\n",
       "      <td>gpt-4o-search-preview Model In LangChain4J - S...</td>\n",
       "      <td>&lt;p&gt;Tonight I received the following from openA...</td>\n",
       "      <td>java;spring-boot;langchain;langchain4j</td>\n",
       "      <td>&lt;blockquote&gt;\\n&lt;p&gt;How do I tell langchain4j to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27783 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      Methods for Geotagging or Geolabelling Text Co...   \n",
       "1            Named Entity Recognition Libraries for Java   \n",
       "2      Algorithms recognizing physical address on a w...   \n",
       "3         Strategies for recognizing proper nouns in NLP   \n",
       "4                Algorithms for named entity recognition   \n",
       "...                                                  ...   \n",
       "27778  Can&#39;t get UUID from similarity search Weav...   \n",
       "27779  When using &#39;interrupt&#39; followed by &#3...   \n",
       "27780                   Precision used in ChromaDB Index   \n",
       "27781  Presidio with Langchain Experimental does not ...   \n",
       "27782  gpt-4o-search-preview Model In LangChain4J - S...   \n",
       "\n",
       "                                             description  \\\n",
       "0      <p>What are some good algorithms for automatic...   \n",
       "1      <p>I am looking for a simple but \"good enough\"...   \n",
       "2      <p>What are the best algorithms for recognizin...   \n",
       "3      <p>I'm interested in learning more about <a hr...   \n",
       "4      <p>I would like to use named entity recognitio...   \n",
       "...                                                  ...   \n",
       "27778  <p>I tried to retrieve documents with similar ...   \n",
       "27779  <p>When I invoke a graph that includes <code>i...   \n",
       "27780  <p>I am using BAAI/bge-large-en-v1.5 model to ...   \n",
       "27781  <p>I am using presidio/langchain_experimental ...   \n",
       "27782  <p>Tonight I received the following from openA...   \n",
       "\n",
       "                                                    tags  \\\n",
       "0      algorithm;statistics;nlp;named-entity-recognition   \n",
       "1                      java;nlp;named-entity-recognition   \n",
       "2      algorithm;screen-scraping;nlp;pattern-matching...   \n",
       "3            nlp;named-entity-recognition;part-of-speech   \n",
       "4      php;python;extract;analysis;named-entity-recog...   \n",
       "...                                                  ...   \n",
       "27778          python;langchain;vector-database;weaviate   \n",
       "27779                     javascript;langchain;langgraph   \n",
       "27780  langchain;embedding;dtype;chromadb;vector-data...   \n",
       "27781                python;nlp;spacy;langchain;presidio   \n",
       "27782             java;spring-boot;langchain;langchain4j   \n",
       "\n",
       "                                         accepted_answer  \n",
       "0      <p>You're looking for a <a href=\"https://secur...  \n",
       "1      <p>BTW, I recently ran across <a href=\"http://...  \n",
       "2      <p>A named-entity extraction framework such as...  \n",
       "3      <p>The task of determining the proper part of ...  \n",
       "4      <p>To start with check out <a href=\"http://www...  \n",
       "...                                                  ...  \n",
       "27778  <p>Duda Nogueira from Weaviate here!</p>\\n<p>C...  \n",
       "27779  <p>I'm an engineer on the LangChain team, and ...  \n",
       "27780  <p>like this:</p>\\n<pre><code>import chromadb\\...  \n",
       "27781  <p>After some test I was able to find the solu...  \n",
       "27782  <blockquote>\\n<p>How do I tell langchain4j to ...  \n",
       "\n",
       "[27783 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df[[\"title\",\"description\",\"tags\",\"accepted_answer\"]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07af51fc",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Stack Apps, 2022. Fetch all questions of a particular tag from the Stack Exchange API in\n",
    "Python. [online] Available at: https://stackapps.com/questions/9436/fetch-all-questions-of-aparticular-tag-from-the-stack-exchange-api-in-python [Accessed 20 Apr. 2025].\n",
    "2. Tewani, Y., 2023. GET request with StackOverflow API, Postman, and Python. [online]\n",
    "Medium. Available at: https://medium.com/@yash.tewani.nyc/get-request-withstackoverflow-api-using-a-python-script-and-postman-f6d34b3f6f57 [Accessed 20 Apr.\n",
    "2025]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
